GOOGLE COLAB SETUP FOR IMPROVED BERT PIPELINE
================================================

STEP 1: Create New Colab Notebook
- Go to https://colab.research.google.com
- Click "New Notebook"
- Enable GPU: Runtime -> Change runtime type -> Hardware accelerator -> GPU

STEP 2: Install Dependencies (Cell 1)
!pip install transformers torch torchvision torchaudio
!pip install scikit-learn matplotlib seaborn tqdm pandas numpy
!pip install huggingface_hub

STEP 3: Upload Data Files (Cell 2)
from google.colab import files
import pandas as pd

print("Upload these files:")
print("1. contact_reports_improved.csv (most important)")
print("2. donors.csv (optional)")
print("3. relationships.csv (optional)")

uploaded = files.upload()

for filename in uploaded.keys():
    print(f"Uploaded: {filename}")

STEP 4: Verify Data (Cell 3)
contact_reports = pd.read_csv('contact_reports_improved.csv')
print(f"Loaded {len(contact_reports):,} improved contact reports")
print(f"Label distribution:")
print(contact_reports['Outcome_Category'].value_counts())

print("\nSample improved reports:")
for i, (_, row) in enumerate(contact_reports.head(3).iterrows()):
    print(f"\n{i+1}. {row['Outcome_Category']}: {row['Report_Text'][:100]}...")

STEP 5: Copy BERT Pipeline Code (Cell 4)
- Copy the ENTIRE content of src/bert_pipeline.py
- Paste it into a new cell
- This includes all the functions and classes

STEP 6: Run BERT Pipeline (Cell 5)
results = run_bert_pipeline_on_contact_reports(
    data_dir=".",  # Current directory in Colab
    model_choice='distilbert',  # Start with fastest
    batch_size=16,
    epochs=5,  # Increased for better training
    learning_rate=2e-5
)

print("Training completed!")
print(f"Test Accuracy: {results['test_accuracy']:.4f}")

STEP 7: Analyze Results (Cell 6)
model = results['model']
trainer = results['trainer']
visualizer = results['visualizer']

# Show training curves
trainer.plot_training_curves()

# Visualize attention
sample_text = "Donor was very interested but needs to think about it."
visualizer.visualize_attention(sample_text)

STEP 8: Performance Analysis (Cell 7)
print("Performance Analysis:")
print(f"Final Test Accuracy: {results['test_accuracy']:.4f}")

if results['test_accuracy'] > 0.95:
    print("WARNING: Accuracy still too high")
elif results['test_accuracy'] > 0.85:
    print("GOOD: Accuracy is in realistic range")
elif results['test_accuracy'] > 0.75:
    print("EXCELLENT: Realistic performance with challenging data")
else:
    print("REVIEW: Accuracy quite low - may need tuning")

EXPECTED RESULTS:
- Test Accuracy: 75-85% (much more realistic than 100%)
- Training time: 20-30 minutes with GPU
- Better performance on minority classes
- More realistic confusion matrix

FILES TO UPLOAD:
1. synthetic_donor_dataset/contact_reports_improved.csv (34,721 records)
2. synthetic_donor_dataset/donors.csv (optional, 50,000 records)
3. synthetic_donor_dataset/relationships.csv (optional)

TROUBLESHOOTING:
- If CUDA out of memory: Reduce batch_size to 8
- If slow training: Use 'distilbert' model
- If low accuracy: Check data upload and preprocessing
- If still 100% accuracy: Verify you're using improved data
