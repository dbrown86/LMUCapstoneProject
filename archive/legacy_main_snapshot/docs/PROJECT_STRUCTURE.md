# LMU CS Capstone Project - Organized Structure

## ğŸ“ Directory Organization

```
LMUCapstoneProject/
â”œâ”€â”€ ğŸ“ config/                    # Configuration files and documentation
â”‚   â”œâ”€â”€ README.md                 # Main project documentation
â”‚   â”œâ”€â”€ requirements_enhanced.txt # Python dependencies
â”‚   â”œâ”€â”€ TESTING_GUIDE.md         # Testing instructions
â”‚   â”œâ”€â”€ TRAINING_PIPELINE_QUICKSTART.md
â”‚   â”œâ”€â”€ TRAINING_RESULTS_SUMMARY.md
â”‚   â”œâ”€â”€ MULTIMODAL_ARCHITECTURE_CHECKLIST.txt
â”‚   â””â”€â”€ PROJECT_EVALUATION_REPORT.txt
â”‚
â”œâ”€â”€ ğŸ“ data/                      # All data files and embeddings
â”‚   â”œâ”€â”€ synthetic_donor_dataset/  # Generated synthetic data
â”‚   â”‚   â”œâ”€â”€ donors.csv
â”‚   â”‚   â”œâ”€â”€ relationships.csv
â”‚   â”‚   â”œâ”€â”€ contact_reports.csv
â”‚   â”‚   â”œâ”€â”€ giving_history.csv
â”‚   â”‚   â”œâ”€â”€ enhanced_fields.csv
â”‚   â”‚   â”œâ”€â”€ challenging_test_cases.csv
â”‚   â”‚   â””â”€â”€ dataset_analysis.png
â”‚   â”œâ”€â”€ bert_embeddings_real.npy  # Pre-computed BERT embeddings
â”‚   â”œâ”€â”€ gnn_embeddings_real.npy   # Pre-computed GNN embeddings
â”‚   â””â”€â”€ enhanced_pipeline_real_embeddings_results.pkl
â”‚
â”œâ”€â”€ ğŸ“ models/                    # Trained models and checkpoints
â”‚   â”œâ”€â”€ best_contact_classifier.pt
â”‚   â”œâ”€â”€ best_donor_gnn_model.pt
â”‚   â””â”€â”€ donor_model_checkpoints/
â”‚       â”œâ”€â”€ best_model.pt
â”‚       â””â”€â”€ training_summary.json
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   # All executable scripts
â”‚   â”œâ”€â”€ main.py                   # Main entry point
â”‚   â”œâ”€â”€ run_interpretability_pipeline.py
â”‚   â”œâ”€â”€ run_improved_pipeline.py
â”‚   â”œâ”€â”€ run_enhanced_pipeline.py
â”‚   â”œâ”€â”€ run_final_optimized_pipeline.py
â”‚   â”œâ”€â”€ run_with_real_embeddings.py
â”‚   â”œâ”€â”€ run_donor_training_simple.py
â”‚   â”œâ”€â”€ extract_real_embeddings.py
â”‚   â”œâ”€â”€ create_capstone_visualizations.py
â”‚   â”œâ”€â”€ install_dependencies.py
â”‚   â””â”€â”€ test_pipeline_setup.py
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bert_pipeline.py          # BERT text processing
â”‚   â”œâ”€â”€ enhanced_ensemble_model.py # Main ensemble model
â”‚   â”œâ”€â”€ enhanced_feature_engineering.py
â”‚   â”œâ”€â”€ enhanced_multimodal_pipeline.py
â”‚   â”œâ”€â”€ model_interpretability.py # SHAP, attention, etc.
â”‚   â”œâ”€â”€ interpretability_integration.py
â”‚   â”œâ”€â”€ multimodal_arch.py        # Multimodal architecture
â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”œâ”€â”€ integrated_trainer.py
â”‚   â”œâ”€â”€ business_metrics_evaluator.py
â”‚   â”œâ”€â”€ class_imbalance_handler.py
â”‚   â”œâ”€â”€ data_generation/          # Synthetic data generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ data_generation.py
â”‚   â”‚   â”œâ”€â”€ donor_generator.py
â”‚   â”‚   â””â”€â”€ validation.py
â”‚   â””â”€â”€ gnn_models/               # Graph Neural Network models
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ gnn_models.py
â”‚       â”œâ”€â”€ gnn_pipeline.py
â”‚       â”œâ”€â”€ gnn_analysis.py
â”‚       â””â”€â”€ dataset_diagnostics.py
â”‚
â”œâ”€â”€ ğŸ“ examples/                  # Example usage scripts
â”‚   â”œâ”€â”€ basic_training_example.py
â”‚   â”œâ”€â”€ donor_prediction_with_pipeline.py
â”‚   â””â”€â”€ interpretability_example.py
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks
â”‚   â””â”€â”€ colab_multimodal_pipeline.ipynb
â”‚
â”œâ”€â”€ ğŸ“ visualizations/            # Generated plots and charts
â”‚   â”œâ”€â”€ dataset_predictability_analysis.png
â”‚   â”œâ”€â”€ donor_training_curves.png
â”‚   â”œâ”€â”€ multimodal_separation_analysis.png
â”‚   â””â”€â”€ multimodal_separation_results.csv
â”‚
â”œâ”€â”€ ğŸ“ docs/                      # Detailed documentation
â”‚   â”œâ”€â”€ INTERPRETABILITY_GUIDE.md
â”‚   â”œâ”€â”€ TRAINING_PIPELINE_GUIDE.md
â”‚   â””â”€â”€ TRAINING_PIPELINE_README.md
â”‚
â”œâ”€â”€ ğŸ“ results/                   # Experiment results (empty, ready for new results)
â”œâ”€â”€ ğŸ“ tests/                     # Unit tests (empty, ready for test files)
â””â”€â”€ ğŸ“ venv/                      # Python virtual environment
```

## ğŸš€ Quick Start Guide

### 1. Setup Environment
```bash
# Navigate to project directory
cd "C:\Desktop\LMU CS Capstone Project\LMUCapstoneProject"

# Activate virtual environment
venv\Scripts\activate

# Install dependencies
pip install -r config\requirements_enhanced.txt
```

### 2. Run Main Scripts
```bash
# Run the main interpretability pipeline
python scripts\run_interpretability_pipeline.py

# Run the improved pipeline with enhanced features
python scripts\run_improved_pipeline.py

# Extract embeddings (if needed)
python scripts\extract_real_embeddings.py
```

### 3. View Results
- **Models**: Check `models/` for trained model files
- **Visualizations**: Check `visualizations/` for generated plots
- **Results**: Check `results/` for experiment outputs
- **Data**: Check `data/` for datasets and embeddings

## ğŸ“‹ Key Features by Directory

### `scripts/` - Main Execution Scripts
- **run_interpretability_pipeline.py**: Complete interpretability analysis
- **run_improved_pipeline.py**: Enhanced pipeline with better features
- **extract_real_embeddings.py**: Generate BERT and GNN embeddings

### `src/` - Core Implementation
- **enhanced_ensemble_model.py**: Main ensemble model with calibration
- **model_interpretability.py**: SHAP, attention, graph importance
- **bert_pipeline.py**: Text processing and BERT integration
- **gnn_models/**: Graph neural network implementations

### `data/` - All Data Files
- **synthetic_donor_dataset/**: Generated synthetic donor data
- **bert_embeddings_real.npy**: Pre-computed text embeddings
- **gnn_embeddings_real.npy**: Pre-computed graph embeddings

### `config/` - Configuration & Documentation
- **README.md**: Main project documentation
- **requirements_enhanced.txt**: Python dependencies
- **TESTING_GUIDE.md**: Testing instructions

## ğŸ”§ Maintenance

### Adding New Scripts
- Place new executable scripts in `scripts/`
- Update this structure document

### Adding New Data
- Place datasets in `data/`
- Place embeddings in `data/`
- Update data loading paths in scripts

### Adding New Models
- Place trained models in `models/`
- Update model loading paths in scripts

### Adding New Visualizations
- Place generated plots in `visualizations/`
- Update visualization saving paths in scripts

## ğŸ“Š Current Status
- âœ… Project structure organized
- âœ… Files moved to appropriate directories
- âœ… Clear separation of concerns
- ğŸ”„ Import paths may need updating in some scripts
- ğŸ”„ Documentation updated to reflect new structure



